{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# textCNN模型\n",
    "textCNN模型主要使⽤了⼀维卷积层和时序最⼤池化层。假设输⼊的⽂本序列由n个词组成，每个词⽤d维的词向量表⽰。那么输⼊样本的宽为n，⾼为1，输⼊通道数为d。textCNN的计算主要分为以下⼏步：\n",
    "\n",
    "1.定义多个⼀维卷积核，并使⽤这些卷积核对输⼊分别做卷积计算。宽度不同的卷积核可能会捕捉到不同个数的相邻词的相关性。\n",
    "\n",
    "2.对输出的所有通道分别做时序最⼤池化，再将这些通道的池化输出值连结为向量。\n",
    "\n",
    "3.通过全连接层将连结后的向量变换为有关各类别的输出。这⼀步可以使⽤丢弃层应对过拟合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalAveragePooling1D, Dense, Concatenate, GlobalMaxPooling1D\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 时序最⼤池化层\n",
    "textCNN中使⽤的时序最⼤池化（max-over-time pooling）层实际上对应⼀维全局最⼤池化层：\\\n",
    "假设输⼊包含多个通道，各通道由不同时间步上的数值组成，各通道的输出即该通道所有时间步中最⼤的数值。\\\n",
    "因此，时序最⼤池化层的输⼊在各个通道上的时间步数可以不同。\\\n",
    "为提升计算性能，我们常常将不同⻓度的时序样本组成⼀个小批量，并通过在较短序列后附加特殊字符（如0）令批量中各时序样本⻓度相同。这些⼈为添加的特殊字符当然是⽆意义的。由于时序最⼤池化的主要⽬的是抓取时序中最重要的特征，它通常能使模型不受⼈为添加字符的影响。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(Model):\n",
    "    \n",
    "    def __init__(self, maxlen, max_features, embedding_dims, class_num, kernel_sizes=[1,2,3], kernel_regularizer=None, last_activation='softmax'):\n",
    "        '''\n",
    "        :param maxlen: 文本最大长度\n",
    "        :param max_features: 词典大小\n",
    "        :param embedding_dims: embedding维度大小\n",
    "        :param kernel_sizes: 滑动卷积窗口大小的list, eg: [1,2,3]\n",
    "        :param kernel_regularizer: eg: tf.keras.regularizers.l2(0.001)\n",
    "        :param class_num:\n",
    "        :param last_activation:\n",
    "        '''\n",
    "        \n",
    "        super(TextCNN, self).__init__()\n",
    "        self.maxlen = maxlen\n",
    "        # self.max_features = max_features\n",
    "        # self.embedding_dims = embedding_dims\n",
    "        self.kernel_sizes = kernel_sizes\n",
    "        self.class_num = class_num\n",
    "        self.embedding = Embedding(input_dim=max_features, output_dim=embedding_dims, input_length=maxlen)\n",
    "        self.conv1s = []\n",
    "        self.avgpools = []\n",
    "        for kernel_size in kernel_sizes:\n",
    "            self.conv1s.append(Conv1D(filters=128, kernel_size=kernel_size, activation='relu', kernel_regularizer=kernel_regularizer))\n",
    "            self.avgpools.append(GlobalMaxPooling1D())\n",
    "        self.classifier = Dense(class_num, activation=last_activation, )\n",
    "        \n",
    "        \n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        if len(inputs.get_shape()) != 2:\n",
    "            raise ValueError('The rank of inputs of TextCNN must be 2, but now is %d' % len(inputs.get_shape()))\n",
    "        if inputs.get_shape()[1] != self.maxlen:\n",
    "            raise ValueError('The maxlen of inputs of TextCNN must be %d, but now is %d' % (self.maxlen, inputs.get_shape()[1]))\n",
    "         \n",
    "        emb = self.embedding(inputs)\n",
    "        conv1s = []\n",
    "        for i in range(len(self.kernel_sizes)):\n",
    "            c = self.conv1s[i](emb) # (batch_size, maxlen-kernel_size+1, filters)\n",
    "            c = self.avgpools[i](c) # # (batch_size, filters)\n",
    "            conv1s.append(c)\n",
    "        x = Concatenate()(conv1s) # (batch_size, len(self.kernel_sizes)*filters)\n",
    "        output = self.classifier(x)\n",
    "        return output\n",
    "    \n",
    "    def build_graph(self, input_shape):\n",
    "        input_shape_nobatch = input_shape[1:]\n",
    "        self.build(input_shape)\n",
    "        inputs = tf.keras.Input(shape=input_shape_nobatch)\n",
    "        if not hasattr(self, 'call'):\n",
    "            raise AttributeError(\"User should define 'call' method in sub-class model!\")\n",
    "        _ = self.call(inputs)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TensorFlow] *",
   "language": "python",
   "name": "conda-env-TensorFlow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
