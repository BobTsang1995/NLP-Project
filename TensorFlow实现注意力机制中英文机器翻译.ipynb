{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import jieba\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "from opencc import OpenCC\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下载和准备数据集\n",
    "我们将使用 http://www.manythings.org/anki/ 提供的一个语言数据集。这个数据集包含如下格式的语言翻译对：\n",
    "\n",
    "I love cake.\t我鐘意蛋糕。\\\n",
    "这个数据集中有很多种语言可供选择。我们将使用英语 - 粤语数据集。下载完数据集后，我们将采取下列步骤准备数据：\n",
    "\n",
    "给每个句子添加一个 开始 和一个 结束 标记（token）。\\\n",
    "预处理语料。\\\n",
    "创建一个单词索引和一个反向单词索引（即一个从单词映射至 id 的词典和一个从 id 映射至单词的词典）。\\\n",
    "将每个句子填充（pad）到最大长度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文件路径\n",
    "\n",
    "path_to_file = \"cmn.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义繁简转换器\n",
    "\n",
    "cc = OpenCC('t2s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['返工', '返成點', '呀', '？']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jieba.lcut(\"返工返成點呀？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(w):\n",
    "    # 英文转小写\n",
    "    w = w.lower().strip()\n",
    "    # 中文繁简转换\n",
    "    w = cc.convert(w)\n",
    "    w = w.rstrip().strip()\n",
    "    # 分词\n",
    "    w = ' '.join(jieba.lcut(w))\n",
    "    # 去除多余空格\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    # 给句子加上开始和结束标记\n",
    "    # 以便模型知道何时开始和结束预测\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> please be ready in fifteen minutes . <end>\n",
      "<start> 有 咩 帮到 你 呢 ？ <end>\n"
     ]
    }
   ],
   "source": [
    "en_sentence = u\"Please be ready in fifteen minutes.\"\n",
    "cn_sentence = u\"有咩幫到你呢？\"\n",
    "# cn_sentence = u\"有什么可以帮到你呢？\"\n",
    "print(preprocess_sentence(en_sentence))\n",
    "print(preprocess_sentence(cn_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 清理句子\n",
    "# 3. 返回这样格式的句子对：[ENGLISH, CHINESE]\n",
    "def create_dataset(path):\n",
    "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "\n",
    "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')[:2]]  for l in lines]\n",
    "\n",
    "    return zip(*word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> if a person has not had a chance to acquire his target language by the time he ' s an adult , he ' s unlikely to be able to reach native speaker level in that language . <end>\n",
      "<start> 如果 一个 人 在 成人 前 没有 机会 习得 目标语言 ， 他 对 该 语言 的 认识 达到 母语 者 程度 的 机会 是 相当 小 的 。 <end>\n"
     ]
    }
   ],
   "source": [
    "en, cn = create_dataset(path_to_file)\n",
    "print(en[-1])\n",
    "print(cn[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    # 创建清理过的输入输出对\n",
    "    targ_lang, inp_lang = create_dataset(path)\n",
    "\n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file)\n",
    "\n",
    "# 计算目标张量的最大长度 （max_length）\n",
    "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18755 18755 4689 4689\n"
     ]
    }
   ],
   "source": [
    "# 采用 80 - 20 的比例切分训练集和验证集\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# 显示长度\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "    for t in tensor:\n",
    "        if t!=0:\n",
    "            print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "7 ----> 你\n",
      "91 ----> 为什么\n",
      "344 ----> 打开\n",
      "25 ----> 这个\n",
      "856 ----> 盒子\n",
      "9 ----> ？\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "110 ----> why\n",
      "59 ----> did\n",
      "8 ----> you\n",
      "256 ----> open\n",
      "6 ----> the\n",
      "510 ----> box\n",
      "10 ----> ?\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建一个 tf.data 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 30]), TensorShape([64, 40]))"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 编写编码器 （encoder） 和解码器 （decoder） 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "编码器采用 Bahdanau 注意力。在用简化形式编写之前，让我们先决定符号：\n",
    "\n",
    "FC = 完全连接（密集）层\\\n",
    "EO = 编码器输出\\\n",
    "H = 隐藏层状态\\\n",
    "X = 解码器输入\\\n",
    "以及伪代码：\n",
    "\n",
    "score = FC(tanh(FC(EO) + FC(H)))\\\n",
    "attention weights = softmax(score, axis = 1)。 \\\n",
    "Softmax 默认被应用于最后一个轴，但是这里我们想将它应用于 第一个轴, 因为分数 （score） 的形状是 (批大小，最大长度，1)。\\\n",
    "最大长度 （max_length） 是我们的输入的长度。因为我们想为每个输入分配一个权重，所以 softmax 应该用在这个轴上。\\\n",
    "context vector = sum(attention weights * EO, axis = 1)。选择第一个轴的原因同上。\\\n",
    "embedding output = 解码器输入 X 通过一个嵌入层。\\\n",
    "merged vector = concat(embedding output, context vector)\\\n",
    "此合并后的向量随后被传送到 GRU\n",
    "每个步骤中所有向量的形状已在代码的注释中阐明："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 30, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# 样本输入\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # 隐藏层的形状 == （批大小，隐藏层大小）\n",
    "        # hidden_with_time_axis 的形状 == （批大小，1，隐藏层大小）\n",
    "        # 这样做是为了执行加法以计算分数\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # 分数的形状 == （批大小，最大长度，1）\n",
    "        # 我们在最后一个轴上得到 1， 因为我们把分数应用于 self.V\n",
    "        # 在应用 self.V 之前，张量的形状是（批大小，最大长度，隐层大小）\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "        # 注意力权重 （attention_weights） 的形状 == （批大小，最大长度，1）\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # 上下文向量 （context_vector） 求和之后的形状 == （批大小，隐藏层大小）\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 30, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # 用于注意力\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # 编码器输出 （enc_output） 的形状 == （批大小，最大长度，隐藏层大小）\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        # x 在通过嵌入层后的形状 == （批大小，1，嵌入维度）\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # x 在拼接 （concatenation） 后的形状 == （批大小，1，嵌入维度 + 隐藏层大小）\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # 将合并后的向量传送到 GRU\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # 输出的形状 == （批大小 * 1，隐藏层大小）\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # 输出的形状 == （批大小，vocab）\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 6532)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((64, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义优化器和损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点（基于对象保存）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练\n",
    "将 输入 传送至 编码器，编码器返回 编码器输出 和 编码器隐藏层状态。\n",
    "\n",
    "将编码器输出、编码器隐藏层状态和解码器输入（即 开始标记）传送至解码器。\n",
    "\n",
    "解码器返回 预测 和 解码器隐藏层状态。\n",
    "\n",
    "解码器隐藏层状态被传送回模型，预测被用于计算损失。\n",
    "\n",
    "使用 强制教学 （teacher forcing） 决定解码器的下一个输入。\n",
    "\n",
    "强制教学 是将 目标词 作为 下一个输入 传送至解码器的技术。\n",
    "\n",
    "最后一步是计算梯度，并将其应用于优化器和反向传播。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "    # 教师强制 - 将目标词作为下一个输入\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      # 将编码器输出 （enc_output） 传送至解码器\n",
    "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      # 使用教师强制\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 2.0315\n",
      "Epoch 1 Batch 100 Loss 1.0228\n",
      "Epoch 1 Batch 200 Loss 0.8622\n",
      "Epoch 1 Loss 1.0171\n",
      "Time taken for 1 epoch 4109.3671243190765 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.8127\n",
      "Epoch 2 Batch 100 Loss 0.7867\n",
      "Epoch 2 Batch 200 Loss 0.7654\n",
      "Epoch 2 Loss 0.7740\n",
      "Time taken for 1 epoch 13567.209409952164 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.6483\n",
      "Epoch 3 Batch 100 Loss 0.5868\n",
      "Epoch 3 Batch 200 Loss 0.5996\n",
      "Epoch 3 Loss 0.6351\n",
      "Time taken for 1 epoch 2344.6578969955444 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.5297\n",
      "Epoch 4 Batch 100 Loss 0.5030\n",
      "Epoch 4 Batch 200 Loss 0.4637\n",
      "Epoch 4 Loss 0.5150\n",
      "Time taken for 1 epoch 2171.951658964157 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.3946\n",
      "Epoch 5 Batch 100 Loss 0.4183\n",
      "Epoch 5 Batch 200 Loss 0.4017\n",
      "Epoch 5 Loss 0.4071\n",
      "Time taken for 1 epoch 2142.007968902588 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.3160\n",
      "Epoch 6 Batch 100 Loss 0.2699\n",
      "Epoch 6 Batch 200 Loss 0.3401\n",
      "Epoch 6 Loss 0.3141\n",
      "Time taken for 1 epoch 2697.31707072258 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.2661\n",
      "Epoch 7 Batch 100 Loss 0.2424\n",
      "Epoch 7 Batch 200 Loss 0.2837\n",
      "Epoch 7 Loss 0.2389\n",
      "Time taken for 1 epoch 2334.899687767029 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.1440\n",
      "Epoch 8 Batch 100 Loss 0.1605\n",
      "Epoch 8 Batch 200 Loss 0.2032\n",
      "Epoch 8 Loss 0.1787\n",
      "Time taken for 1 epoch 2215.4181530475616 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.1085\n",
      "Epoch 9 Batch 100 Loss 0.1345\n",
      "Epoch 9 Batch 200 Loss 0.1280\n",
      "Epoch 9 Loss 0.1340\n",
      "Time taken for 1 epoch 2197.6847071647644 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0822\n",
      "Epoch 10 Batch 100 Loss 0.1054\n",
      "Epoch 10 Batch 200 Loss 0.1140\n",
      "Epoch 10 Loss 0.1002\n",
      "Time taken for 1 epoch 2212.640686273575 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                         batch,\n",
    "                                                         batch_loss.numpy()))\n",
    "  # 每 2 个周期（epoch），保存（检查点）一次模型\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 翻译\n",
    "评估函数类似于训练循环，不同之处在于在这里我们不使用 教师强制。每个时间步的解码器输入是其先前的预测、隐藏层状态和编码器输出。\\\n",
    "当模型预测 结束标记 时停止预测。\\\n",
    "存储 每个时间步的注意力权重。\\\n",
    "请注意：对于一个输入，编码器输出仅计算一次。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "    \n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    \n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                           maxlen=max_length_inp,\n",
    "                                                           padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    \n",
    "    result = ''\n",
    "    \n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "    \n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "    \n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "    \n",
    "        # 存储注意力权重以便后面制图\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "    \n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "    \n",
    "        result += targ_lang.index_word[predicted_id] + ' '\n",
    "    \n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "    \n",
    "        # 预测的 ID 被输送回模型\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "    \n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib显示中文\n",
    "# !wget -O /Users/bob/simhei.ttf \"https://www.wfonts.com/download/data/2014/06/01/simhei/chinese.simhei.ttf\"\n",
    "# -*- coding: utf-8 -*-\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "# zhfont = mpl.font_manager.FontProperties(fname='simhei.ttf')\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意力权重制图函数\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f8c829f6190>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 恢复检查点目录 （checkpoint_dir） 中最新的检查点\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> 你 会 说 英语 么 ？ <end>\n",
      "Predicted translation: do you speak english ? <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'你会说英语么？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> 我 知道 那些 夏天 就 像 你 一样 不 回来 。 <end>\n",
      "Predicted translation: i know those stay well . <end> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bob/opt/anaconda3/envs/TensorFlow/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 25105 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/bob/opt/anaconda3/envs/TensorFlow/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 30693 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/bob/opt/anaconda3/envs/TensorFlow/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 36947 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/bob/opt/anaconda3/envs/TensorFlow/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 37027 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/bob/opt/anaconda3/envs/TensorFlow/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 20123 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/bob/opt/anaconda3/envs/TensorFlow/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 22799 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/bob/opt/anaconda3/envs/TensorFlow/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 22825 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/bob/opt/anaconda3/envs/TensorFlow/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 23601 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/bob/opt/anaconda3/envs/TensorFlow/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 20687 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/bob/opt/anaconda3/envs/TensorFlow/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 26679 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/bob/opt/anaconda3/envs/TensorFlow/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 19981 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/bob/opt/anaconda3/envs/TensorFlow/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 22238 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/bob/opt/anaconda3/envs/TensorFlow/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 26469 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/bob/opt/anaconda3/envs/TensorFlow/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 25105 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/bob/opt/anaconda3/envs/TensorFlow/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 30693 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/bob/opt/anaconda3/envs/TensorFlow/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 36947 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/bob/opt/anaconda3/envs/TensorFlow/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 37027 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/bob/opt/anaconda3/envs/TensorFlow/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 20123 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/bob/opt/anaconda3/envs/TensorFlow/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 22799 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/bob/opt/anaconda3/envs/TensorFlow/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 22825 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/bob/opt/anaconda3/envs/TensorFlow/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 23601 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/bob/opt/anaconda3/envs/TensorFlow/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 20687 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/bob/opt/anaconda3/envs/TensorFlow/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 26679 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/bob/opt/anaconda3/envs/TensorFlow/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 19981 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/bob/opt/anaconda3/envs/TensorFlow/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 22238 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/bob/opt/anaconda3/envs/TensorFlow/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 26469 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'我知道那些夏天就像你一样不回来。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> 没 问题 。 <end>\n",
      "Predicted translation: no problem . <end> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bob/opt/anaconda3/envs/TensorFlow/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 27809 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/bob/opt/anaconda3/envs/TensorFlow/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 27809 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'没問題。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TensorFlow] *",
   "language": "python",
   "name": "conda-env-TensorFlow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
