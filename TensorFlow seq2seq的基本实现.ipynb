{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据是一个元组列表，其中每个元组包含一个英语句子和一个法语句子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = (\n",
    "    ('What a ridiculous concept!', 'Quel concept ridicule !'),\n",
    "    ('Your idea is not entirely crazy.', \"Votre idée n'est pas complètement folle.\"),\n",
    "    (\"A man's worth lies in what he is.\", \"La valeur d'un homme réside dans ce qu'il est.\"),\n",
    "    ('What he did is very wrong.', \"Ce qu'il a fait est très mal.\"),\n",
    "    (\"All three of you need to do that.\", \"Vous avez besoin de faire cela, tous les trois.\"),\n",
    "    (\"Are you giving me another chance?\", \"Me donnez-vous une autre chance ?\"),\n",
    "    (\"Both Tom and Mary work as models.\", \"Tom et Mary travaillent tous les deux comme mannequins.\"),\n",
    "    (\"Can I have a few minutes, please?\", \"Puis-je avoir quelques minutes, je vous prie ?\"),\n",
    "    (\"Could you close the door, please?\", \"Pourriez-vous fermer la porte, s'il vous plaît ?\"),\n",
    "    (\"Did you plant pumpkins this year?\", \"Cette année, avez-vous planté des citrouilles ?\"),\n",
    "    (\"Do you ever study in the library?\", \"Est-ce que vous étudiez à la bibliothèque des fois ?\"),\n",
    "    (\"Don't be deceived by appearances.\", \"Ne vous laissez pas abuser par les apparences.\"),\n",
    "    (\"Excuse me. Can you speak English?\", \"Je vous prie de m'excuser ! Savez-vous parler anglais ?\"),\n",
    "    (\"Few people know the true meaning.\", \"Peu de gens savent ce que cela veut réellement dire.\"),\n",
    "    (\"Germany produced many scientists.\", \"L'Allemagne a produit beaucoup de scientifiques.\"),\n",
    "    (\"Guess whose birthday it is today.\", \"Devine de qui c'est l'anniversaire, aujourd'hui !\"),\n",
    "    (\"He acted like he owned the place.\", \"Il s'est comporté comme s'il possédait l'endroit.\"),\n",
    "    (\"Honesty will pay in the long run.\", \"L'honnêteté paye à la longue.\"),\n",
    "    (\"How do we know this isn't a trap?\", \"Comment savez-vous qu'il ne s'agit pas d'un piège ?\"),\n",
    "    (\"I can't believe you're giving up.\", \"Je n'arrive pas à croire que vous abandonniez.\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理\n",
    "我们需要稍微清理原始数据。 这种任务通常包括规范化字符串，过滤不需要的字符，在标点符号前添加空格等。大多数时候，需要两个函数，如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def normalize_string(s):\n",
    "    s = unicode_to_ascii(s)\n",
    "    s = re.sub(r'([!.?])', r' \\1', s)\n",
    "    s = re.sub(r'[^a-zA-Z.!?]+', r' ', s)\n",
    "    s = re.sub(r'\\s+', r' ', s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们现在将数据拆分为两个单独的列表，每个列表包含自己的句子。 然后我们将应用上面的函数并添加两个特殊标记：<start>和<end>："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_en, raw_data_fr = list(zip(*raw_data))\n",
    "raw_data_en, raw_data_fr = list(raw_data_en), list(raw_data_fr)\n",
    "\n",
    "raw_data_en = [normalize_string(data) for data in raw_data_en]\n",
    "raw_data_fr_in = ['<start> ' + normalize_string(data) for data in raw_data_fr]\n",
    "raw_data_fr_out = [normalize_string(data) + ' <end>' for data in raw_data_fr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What a ridiculous concept !', 'Your idea is not entirely crazy .', 'A man s worth lies in what he is .', 'What he did is very wrong .', 'All three of you need to do that .', 'Are you giving me another chance ?', 'Both Tom and Mary work as models .', 'Can I have a few minutes please ?', 'Could you close the door please ?', 'Did you plant pumpkins this year ?', 'Do you ever study in the library ?', 'Don t be deceived by appearances .', 'Excuse me . Can you speak English ?', 'Few people know the true meaning .', 'Germany produced many scientists .', 'Guess whose birthday it is today .', 'He acted like he owned the place .', 'Honesty will pay in the long run .', 'How do we know this isn t a trap ?', 'I can t believe you re giving up .']\n",
      "['<start> Quel concept ridicule !', '<start> Votre idee n est pas completement folle .', '<start> La valeur d un homme reside dans ce qu il est .', '<start> Ce qu il a fait est tres mal .', '<start> Vous avez besoin de faire cela tous les trois .', '<start> Me donnez vous une autre chance ?', '<start> Tom et Mary travaillent tous les deux comme mannequins .', '<start> Puis je avoir quelques minutes je vous prie ?', '<start> Pourriez vous fermer la porte s il vous plait ?', '<start> Cette annee avez vous plante des citrouilles ?', '<start> Est ce que vous etudiez a la bibliotheque des fois ?', '<start> Ne vous laissez pas abuser par les apparences .', '<start> Je vous prie de m excuser ! Savez vous parler anglais ?', '<start> Peu de gens savent ce que cela veut reellement dire .', '<start> L Allemagne a produit beaucoup de scientifiques .', '<start> Devine de qui c est l anniversaire aujourd hui !', '<start> Il s est comporte comme s il possedait l endroit .', '<start> L honnetete paye a la longue .', '<start> Comment savez vous qu il ne s agit pas d un piege ?', '<start> Je n arrive pas a croire que vous abandonniez .']\n",
      "['Quel concept ridicule ! <end>', 'Votre idee n est pas completement folle . <end>', 'La valeur d un homme reside dans ce qu il est . <end>', 'Ce qu il a fait est tres mal . <end>', 'Vous avez besoin de faire cela tous les trois . <end>', 'Me donnez vous une autre chance ? <end>', 'Tom et Mary travaillent tous les deux comme mannequins . <end>', 'Puis je avoir quelques minutes je vous prie ? <end>', 'Pourriez vous fermer la porte s il vous plait ? <end>', 'Cette annee avez vous plante des citrouilles ? <end>', 'Est ce que vous etudiez a la bibliotheque des fois ? <end>', 'Ne vous laissez pas abuser par les apparences . <end>', 'Je vous prie de m excuser ! Savez vous parler anglais ? <end>', 'Peu de gens savent ce que cela veut reellement dire . <end>', 'L Allemagne a produit beaucoup de scientifiques . <end>', 'Devine de qui c est l anniversaire aujourd hui ! <end>', 'Il s est comporte comme s il possedait l endroit . <end>', 'L honnetete paye a la longue . <end>', 'Comment savez vous qu il ne s agit pas d un piege ? <end>', 'Je n arrive pas a croire que vous abandonniez . <end>']\n"
     ]
    }
   ],
   "source": [
    "print(raw_data_en)\n",
    "print(raw_data_fr_in)\n",
    "print(raw_data_fr_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seq2Seq模型由两个网络组成：编码器和解码器。 编码器位于左侧，仅需要源语言的序列作为输入。\n",
    "\n",
    "另一方面，解码器需要两种版本的目标语言序列，一种用于输入，一种用于目标（Loss计算）。 解码器本身通常被称为语言模型。\n",
    "\n",
    "从实验中，我还发现最好不要将<start>和<end>标记添加到源序列中。 这样做会使模型，尤其是后来的注意机制混淆，因为所有序列都以相同的标记开头。\n",
    "\n",
    "接下来，让我们看看如何标记数据，即将原始字符串转换为整数序列。 我们将使用Keras的文本标记化实用程序类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意filters参数。 默认情况下，Keras的Tokenizer会删除所有标点符号，这不是我们想要的。 由于我们已经过滤掉了标点符号（！？），我们可以在此处将过滤器设置为空白。\n",
    "\n",
    "标记化的关键部分是词汇。 Keras的Tokenizer类附带了一些方法。 由于我们的数据包含原始字符串，因此我们将使用名为fit_on_texts的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tokenizer.fit_on_texts(raw_data_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'.': 1, 'you': 2, '?': 3, 'the': 4, 'a': 5, 'is': 6, 'he': 7, 'what': 8, 'in': 9, 'do': 10, 'can': 11, 't': 12, 'did': 13, 'giving': 14, 'me': 15, 'i': 16, 'few': 17, 'please': 18, 'this': 19, 'know': 20, 'ridiculous': 21, 'concept': 22, '!': 23, 'your': 24, 'idea': 25, 'not': 26, 'entirely': 27, 'crazy': 28, 'man': 29, 's': 30, 'worth': 31, 'lies': 32, 'very': 33, 'wrong': 34, 'all': 35, 'three': 36, 'of': 37, 'need': 38, 'to': 39, 'that': 40, 'are': 41, 'another': 42, 'chance': 43, 'both': 44, 'tom': 45, 'and': 46, 'mary': 47, 'work': 48, 'as': 49, 'models': 50, 'have': 51, 'minutes': 52, 'could': 53, 'close': 54, 'door': 55, 'plant': 56, 'pumpkins': 57, 'year': 58, 'ever': 59, 'study': 60, 'library': 61, 'don': 62, 'be': 63, 'deceived': 64, 'by': 65, 'appearances': 66, 'excuse': 67, 'speak': 68, 'english': 69, 'people': 70, 'true': 71, 'meaning': 72, 'germany': 73, 'produced': 74, 'many': 75, 'scientists': 76, 'guess': 77, 'whose': 78, 'birthday': 79, 'it': 80, 'today': 81, 'acted': 82, 'like': 83, 'owned': 84, 'place': 85, 'honesty': 86, 'will': 87, 'pay': 88, 'long': 89, 'run': 90, 'how': 91, 'we': 92, 'isn': 93, 'trap': 94, 'believe': 95, 're': 96, 'up': 97}\n"
     ]
    }
   ],
   "source": [
    "print(en_tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们现在可以将原始英语句子转换为整数序列："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_en = en_tokenizer.texts_to_sequences(raw_data_en) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，我们需要填充零，以便所有序列具有相同的长度。 否则，我们以后将无法创建tf.data.Dataset对象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_en = tf.keras.preprocessing.sequence.pad_sequences(data_en,\n",
    "                                                        padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  5 21 22 23  0  0  0  0  0]\n",
      " [24 25  6 26 27 28  1  0  0  0]\n",
      " [ 5 29 30 31 32  9  8  7  6  1]]\n"
     ]
    }
   ],
   "source": [
    "print(data_en[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "继续用法语句子做同样的事情："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "\n",
    "# ATTENTION: always finish with fit_on_texts before moving on\n",
    "fr_tokenizer.fit_on_texts(raw_data_fr_in)\n",
    "fr_tokenizer.fit_on_texts(raw_data_fr_out)\n",
    "\n",
    "data_fr_in = fr_tokenizer.texts_to_sequences(raw_data_fr_in)\n",
    "data_fr_in = tf.keras.preprocessing.sequence.pad_sequences(data_fr_in,\n",
    "                                                           padding='post')\n",
    "\n",
    "data_fr_out = fr_tokenizer.texts_to_sequences(raw_data_fr_out)\n",
    "data_fr_out = tf.keras.preprocessing.sequence.pad_sequences(data_fr_out,\n",
    "                                                            padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit_on_text(texts) :使用一系列文档来生成token词典，texts为list类，每个元素为一个文档。\n",
    "\n",
    "texts_to_sequences(texts):将多个文档转换为word下标的向量形式,shape为[len(texts)，len(text)] -- (文档数，每条文档的长度)\n",
    "\n",
    "texts_to_matrix(texts): 将多个文档转换为矩阵表示,shape为[len(texts),num_words]\n",
    "\n",
    "我们可以在不同的语料库上多次调用fit_on_texts，它会自动更新词汇表。 在使用texts_to_sequences之前，请务必先记得fit_on_texts。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后一步很简单，我们只需要创建一个tf.data.Dataset的实例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (data_en, data_fr_in, data_fr_out))\n",
    "dataset = dataset.shuffle(20).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 没有注意力机制的Seq2Seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但现在，我们可能已经知道注意机制是机器翻译任务的“标准配置”。 但我首先实现没有注意力机制的Seq2Seq作为baseline。\n",
    "\n",
    "实验过程中，我们会感受到：\n",
    "\n",
    "使用最新的TensorFlow2.0的tf.keras非常简单\n",
    "能够回答：为什么需要注意力机制？\n",
    "\n",
    "我们将从编码器开始。 在编码器内部，存在嵌入层和RNN层（可以是简单RNN或LSTM或GRU）实验中我们使用的是LSTM。 在每个前向传递中，它接收一批序列和初始状态并返回输出序列以及最终状态："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, lstm_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.lstm_size = lstm_size\n",
    "        # Embedding Layer\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        # Encode LSTM Layer\n",
    "        self.lstm = tf.keras.layers.LSTM(\n",
    "            lstm_size, return_sequences=True, return_state=True)\n",
    "\n",
    "    def call(self, sequence, states):\n",
    "        embed = self.embedding(sequence)\n",
    "        output, state_h, state_c = self.lstm(embed, initial_state=states)\n",
    "\n",
    "        return output, state_h, state_c\n",
    "\n",
    "    def init_states(self, batch_size):\n",
    "        return (tf.zeros([batch_size, self.lstm_size]),\n",
    "                tf.zeros([batch_size, self.lstm_size]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们已经完成了编码器。 接下来，让我们创建解码器。 没有注意机制的情况下，解码器基本上与编码器相同，只是它有一个Dense层将RNN的输出映射到词汇空间："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, lstm_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.lstm_size = lstm_size\n",
    "        # Embedding Layer\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        # Decode LSTM Layer\n",
    "        self.lstm = tf.keras.layers.LSTM(\n",
    "            lstm_size, return_sequences=True, return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, sequence, state):\n",
    "        embed = self.embedding(sequence)\n",
    "        lstm_out, state_h, state_c = self.lstm(embed, state)\n",
    "        logits = self.dense(lstm_out)\n",
    "\n",
    "        return logits, state_h, state_c\n",
    "\n",
    "    def init_states(self, batch_size):\n",
    "        return (tf.zeros([batch_size, self.lstm_size]),\n",
    "                tf.zeros([batch_size, self.lstm_size]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "编码器的最终状态将充当解码器的初始状态。 这是Seq2Seq模型的语言模型和解码器之间的差异。这就是我们需要创建的解码器。 在继续之前，让我们检查一下我们是否没有犯任何错误："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source sequences (1, 8)\n",
      "Encoder outputs (1, 8, 64)\n",
      "Encoder state_h (1, 64)\n",
      "Encoder state_c (1, 64)\n",
      "\n",
      "Destination vocab size 110\n",
      "Destination sequences (1, 7)\n",
      "Decoder outputs (1, 7, 110)\n",
      "Decoder state_h (1, 64)\n",
      "Decoder state_c (1, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nSource sequences (1, 8)\\nEncoder outputs (1, 8, 64)\\nEncoder state_h (1, 64)\\nEncoder state_c (1, 64)\\nDestination vocab size 107\\nDestination sequences (1, 7)\\nDecoder outputs (1, 7, 107)\\nDecoder state_h (1, 64)\\nDecoder state_c (1, 64)\\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDDING_SIZE = 32\n",
    "LSTM_SIZE = 64\n",
    "\n",
    "en_vocab_size = len(en_tokenizer.word_index) + 1\n",
    "encoder = Encoder(en_vocab_size, EMBEDDING_SIZE, LSTM_SIZE)\n",
    "\n",
    "fr_vocab_size = len(fr_tokenizer.word_index) + 1\n",
    "decoder = Decoder(fr_vocab_size, EMBEDDING_SIZE, LSTM_SIZE)\n",
    "\n",
    "source_input = tf.constant([[1, 3, 5, 7, 2, 0, 0, 0]])\n",
    "initial_state = encoder.init_states(1)\n",
    "encoder_output, en_state_h, en_state_c = encoder(source_input, initial_state)\n",
    "\n",
    "target_input = tf.constant([[1, 4, 6, 9, 2, 0, 0]])\n",
    "decoder_output, de_state_h, de_state_c = decoder(target_input, (en_state_h, en_state_c))\n",
    "\n",
    "print('Source sequences', source_input.shape)\n",
    "print('Encoder outputs', encoder_output.shape)\n",
    "print('Encoder state_h', en_state_h.shape)\n",
    "print('Encoder state_c', en_state_c.shape)\n",
    "\n",
    "print('\\nDestination vocab size', fr_vocab_size)\n",
    "print('Destination sequences', target_input.shape)\n",
    "print('Decoder outputs', decoder_output.shape)\n",
    "print('Decoder state_h', de_state_h.shape)\n",
    "print('Decoder state_c', de_state_c.shape)\n",
    "\n",
    "'''\n",
    "Source sequences (1, 8)\n",
    "Encoder outputs (1, 8, 64)\n",
    "Encoder state_h (1, 64)\n",
    "Encoder state_c (1, 64)\n",
    "Destination vocab size 107\n",
    "Destination sequences (1, 7)\n",
    "Decoder outputs (1, 7, 107)\n",
    "Decoder state_h (1, 64)\n",
    "Decoder state_c (1, 64)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来要做的是定义一个损失函数。 由于我们将零填充到序列中，因此在计算损失时不要考虑这些零："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(targets, logits):\n",
    "    crossentropy = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True)\n",
    "    mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
    "    mask = tf.cast(mask, dtype=tf.int64)\n",
    "    loss = crossentropy(targets, logits, sample_weight=mask)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在创建训练循环之前，让我们定义一个用于推理目的的方法。 它的作用基本上是前向传递，但是我们将输入<start>标识，而不是目标序列。 每个下一个时间步都将最后一个时间步的输出作为输入，直到我们点击<end>标记或输出序列超过特定长度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_source_text=None):\n",
    "    if test_source_text is None:\n",
    "        test_source_text = raw_data_en[np.random.choice(len(raw_data_en))]\n",
    "    print(test_source_text)\n",
    "    test_source_seq = en_tokenizer.texts_to_sequences([test_source_text])\n",
    "    print(test_source_seq)\n",
    "\n",
    "    en_initial_states = encoder.init_states(1)\n",
    "    en_outputs = encoder(tf.constant(test_source_seq), en_initial_states)\n",
    "\n",
    "    de_input = tf.constant([[fr_tokenizer.word_index['<start>']]])\n",
    "    de_state_h, de_state_c = en_outputs[1:]\n",
    "    out_words = []\n",
    "\n",
    "    while True:\n",
    "        de_output, de_state_h, de_state_c = decoder(\n",
    "            de_input, (de_state_h, de_state_c))\n",
    "        de_input = tf.argmax(de_output, -1)\n",
    "        out_words.append(fr_tokenizer.index_word[de_input.numpy()[0][0]])\n",
    "\n",
    "        if out_words[-1] == '<end>' or len(out_words) >= 20:\n",
    "            break\n",
    "\n",
    "    print(' '.join(out_words))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们已经准备好创建训练函数，我们执行前向传递，然后是反向传播。 有两件事需要记住：\n",
    "\n",
    "我们使用@tf.function装饰器来推进静态图形计算（当你想调试时删除它）\n",
    "\n",
    "计算需要放在tf.GradientTape（）下以跟踪Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(source_seq, target_seq_in, target_seq_out, en_initial_states):\n",
    "    with tf.GradientTape() as tape:\n",
    "        en_outputs = encoder(source_seq, en_initial_states)\n",
    "        en_states = en_outputs[1:]\n",
    "        de_states = en_states\n",
    "\n",
    "        de_outputs = decoder(target_seq_in, de_states)\n",
    "        logits = de_outputs[0]\n",
    "        loss = loss_func(target_seq_out, logits)\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，这里是训练循环。 在每个训练批次，我们都会抓取批量数据还打印出损失值并查看模型在每个批次结束时的表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 3.4896\n",
      "Did you plant pumpkins this year ?\n",
      "[[13, 2, 56, 57, 19, 58, 3]]\n",
      "est <end>\n",
      "Epoch 2 Loss 3.6161\n",
      "Did you plant pumpkins this year ?\n",
      "[[13, 2, 56, 57, 19, 58, 3]]\n",
      "vous <end>\n",
      "Epoch 3 Loss 3.7476\n",
      "A man s worth lies in what he is .\n",
      "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
      "vous <end>\n",
      "Epoch 4 Loss 3.3962\n",
      "Both Tom and Mary work as models .\n",
      "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
      "a <end>\n",
      "Epoch 5 Loss 3.6558\n",
      "Honesty will pay in the long run .\n",
      "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
      "vous <end>\n",
      "Epoch 6 Loss 3.6598\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "vous <end>\n",
      "Epoch 7 Loss 3.2174\n",
      "Guess whose birthday it is today .\n",
      "[[77, 78, 79, 80, 6, 81, 1]]\n",
      "<end>\n",
      "Epoch 8 Loss 3.0991\n",
      "Few people know the true meaning .\n",
      "[[17, 70, 20, 4, 71, 72, 1]]\n",
      "<end>\n",
      "Epoch 9 Loss 3.0893\n",
      "What he did is very wrong .\n",
      "[[8, 7, 13, 6, 33, 34, 1]]\n",
      "<end>\n",
      "Epoch 10 Loss 3.0291\n",
      "Germany produced many scientists .\n",
      "[[73, 74, 75, 76, 1]]\n",
      "vous <end>\n",
      "Epoch 11 Loss 3.1738\n",
      "A man s worth lies in what he is .\n",
      "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
      "vous vous <end>\n",
      "Epoch 12 Loss 2.7645\n",
      "Could you close the door please ?\n",
      "[[53, 2, 54, 4, 55, 18, 3]]\n",
      "vous vous vous vous <end>\n",
      "Epoch 13 Loss 2.7023\n",
      "A man s worth lies in what he is .\n",
      "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
      "vous vous vous vous vous <end>\n",
      "Epoch 14 Loss 2.8089\n",
      "What he did is very wrong .\n",
      "[[8, 7, 13, 6, 33, 34, 1]]\n",
      "vous vous vous vous <end>\n",
      "Epoch 15 Loss 3.1043\n",
      "I can t believe you re giving up .\n",
      "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
      "vous vous vous vous vous <end>\n",
      "Epoch 16 Loss 3.1927\n",
      "Germany produced many scientists .\n",
      "[[73, 74, 75, 76, 1]]\n",
      "vous vous vous vous <end>\n",
      "Epoch 17 Loss 2.5380\n",
      "Could you close the door please ?\n",
      "[[53, 2, 54, 4, 55, 18, 3]]\n",
      "vous vous vous vous vous <end>\n",
      "Epoch 18 Loss 2.8489\n",
      "I can t believe you re giving up .\n",
      "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
      "vous vous vous vous vous <end>\n",
      "Epoch 19 Loss 3.1623\n",
      "Don t be deceived by appearances .\n",
      "[[62, 12, 63, 64, 65, 66, 1]]\n",
      "vous vous vous vous <end>\n",
      "Epoch 20 Loss 2.9364\n",
      "Did you plant pumpkins this year ?\n",
      "[[13, 2, 56, 57, 19, 58, 3]]\n",
      "vous vous vous vous vous <end>\n",
      "Epoch 21 Loss 2.7084\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "vous vous vous <end>\n",
      "Epoch 22 Loss 2.8683\n",
      "Did you plant pumpkins this year ?\n",
      "[[13, 2, 56, 57, 19, 58, 3]]\n",
      "vous vous vous vous <end>\n",
      "Epoch 23 Loss 2.3775\n",
      "Excuse me . Can you speak English ?\n",
      "[[67, 15, 1, 11, 2, 68, 69, 3]]\n",
      "vous vous vous vous vous <end>\n",
      "Epoch 24 Loss 2.6009\n",
      "He acted like he owned the place .\n",
      "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
      "vous vous vous vous vous <end>\n",
      "Epoch 25 Loss 2.7809\n",
      "Guess whose birthday it is today .\n",
      "[[77, 78, 79, 80, 6, 81, 1]]\n",
      "<end>\n",
      "Epoch 26 Loss 2.5984\n",
      "How do we know this isn t a trap ?\n",
      "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
      "vous vous vous vous vous vous vous ? <end>\n",
      "Epoch 27 Loss 2.7187\n",
      "Excuse me . Can you speak English ?\n",
      "[[67, 15, 1, 11, 2, 68, 69, 3]]\n",
      "vous vous vous vous vous <end>\n",
      "Epoch 28 Loss 2.7816\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "vous vous <end>\n",
      "Epoch 29 Loss 2.4659\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "vous <end>\n",
      "Epoch 30 Loss 2.6118\n",
      "Germany produced many scientists .\n",
      "[[73, 74, 75, 76, 1]]\n",
      "vous vous <end>\n",
      "Epoch 31 Loss 2.7458\n",
      "A man s worth lies in what he is .\n",
      "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
      "la <end>\n",
      "Epoch 32 Loss 2.4260\n",
      "Are you giving me another chance ?\n",
      "[[41, 2, 14, 15, 42, 43, 3]]\n",
      "vous vous vous vous <end>\n",
      "Epoch 33 Loss 2.5027\n",
      "Honesty will pay in the long run .\n",
      "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
      "vous vous vous vous <end>\n",
      "Epoch 34 Loss 2.0492\n",
      "Germany produced many scientists .\n",
      "[[73, 74, 75, 76, 1]]\n",
      "vous vous <end>\n",
      "Epoch 35 Loss 2.7802\n",
      "All three of you need to do that .\n",
      "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
      "vous vous vous vous vous ? <end>\n",
      "Epoch 36 Loss 2.6204\n",
      "Your idea is not entirely crazy .\n",
      "[[24, 25, 6, 26, 27, 28, 1]]\n",
      "je vous vous <end>\n",
      "Epoch 37 Loss 2.5577\n",
      "Did you plant pumpkins this year ?\n",
      "[[13, 2, 56, 57, 19, 58, 3]]\n",
      "vous vous vous vous <end>\n",
      "Epoch 38 Loss 2.2515\n",
      "Germany produced many scientists .\n",
      "[[73, 74, 75, 76, 1]]\n",
      "je vous vous <end>\n",
      "Epoch 39 Loss 2.5005\n",
      "What he did is very wrong .\n",
      "[[8, 7, 13, 6, 33, 34, 1]]\n",
      "vous vous vous <end>\n",
      "Epoch 40 Loss 2.1772\n",
      "Honesty will pay in the long run .\n",
      "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
      "vous vous a <end>\n",
      "Epoch 41 Loss 2.3153\n",
      "Guess whose birthday it is today .\n",
      "[[77, 78, 79, 80, 6, 81, 1]]\n",
      "<end>\n",
      "Epoch 42 Loss 2.4055\n",
      "Could you close the door please ?\n",
      "[[53, 2, 54, 4, 55, 18, 3]]\n",
      "vous vous vous vous ? <end>\n",
      "Epoch 43 Loss 2.5676\n",
      "Don t be deceived by appearances .\n",
      "[[62, 12, 63, 64, 65, 66, 1]]\n",
      "vous vous a <end>\n",
      "Epoch 44 Loss 2.7867\n",
      "All three of you need to do that .\n",
      "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
      "vous vous vous vous vous ? <end>\n",
      "Epoch 45 Loss 2.2291\n",
      "He acted like he owned the place .\n",
      "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
      "vous vous vous vous ? <end>\n",
      "Epoch 46 Loss 2.0589\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "l l l l l l l l l . <end>\n",
      "Epoch 47 Loss 2.2513\n",
      "Guess whose birthday it is today .\n",
      "[[77, 78, 79, 80, 6, 81, 1]]\n",
      "<end>\n",
      "Epoch 48 Loss 2.3167\n",
      "Your idea is not entirely crazy .\n",
      "[[24, 25, 6, 26, 27, 28, 1]]\n",
      "je je a a <end>\n",
      "Epoch 49 Loss 2.4269\n",
      "Germany produced many scientists .\n",
      "[[73, 74, 75, 76, 1]]\n",
      "je a de de . <end>\n",
      "Epoch 50 Loss 2.1896\n",
      "What he did is very wrong .\n",
      "[[8, 7, 13, 6, 33, 34, 1]]\n",
      "vous a a <end>\n",
      "Epoch 51 Loss 2.2969\n",
      "Honesty will pay in the long run .\n",
      "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
      "l a a a . <end>\n",
      "Epoch 52 Loss 2.3794\n",
      "I can t believe you re giving up .\n",
      "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
      "vous vous vous vous cela cela ? <end>\n",
      "Epoch 53 Loss 1.7353\n",
      "Can I have a few minutes please ?\n",
      "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
      "je je a a a vous . <end>\n",
      "Epoch 54 Loss 2.3042\n",
      "Don t be deceived by appearances .\n",
      "[[62, 12, 63, 64, 65, 66, 1]]\n",
      "vous vous pas ? <end>\n",
      "Epoch 55 Loss 2.0879\n",
      "Did you plant pumpkins this year ?\n",
      "[[13, 2, 56, 57, 19, 58, 3]]\n",
      "vous vous a cela . <end>\n",
      "Epoch 56 Loss 2.2090\n",
      "Did you plant pumpkins this year ?\n",
      "[[13, 2, 56, 57, 19, 58, 3]]\n",
      "vous vous vous ? <end>\n",
      "Epoch 57 Loss 2.2467\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "l l l l l l l l l l l l l l l l l l l l\n",
      "Epoch 58 Loss 1.5922\n",
      "Few people know the true meaning .\n",
      "[[17, 70, 20, 4, 71, 72, 1]]\n",
      "l a a a de . <end>\n",
      "Epoch 59 Loss 2.0949\n",
      "Excuse me . Can you speak English ?\n",
      "[[67, 15, 1, 11, 2, 68, 69, 3]]\n",
      "vous vous vous vous cela ? ? <end>\n",
      "Epoch 60 Loss 1.9941\n",
      "Did you plant pumpkins this year ?\n",
      "[[13, 2, 56, 57, 19, 58, 3]]\n",
      "vous vous vous ? <end>\n",
      "Epoch 61 Loss 2.0435\n",
      "How do we know this isn t a trap ?\n",
      "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
      "vous vous vous vous vous s ? ? <end>\n",
      "Epoch 62 Loss 1.7597\n",
      "Few people know the true meaning .\n",
      "[[17, 70, 20, 4, 71, 72, 1]]\n",
      "l a a a la . <end>\n",
      "Epoch 63 Loss 1.7010\n",
      "Did you plant pumpkins this year ?\n",
      "[[13, 2, 56, 57, 19, 58, 3]]\n",
      "vous vous vous ? <end>\n",
      "Epoch 64 Loss 1.5276\n",
      "Do you ever study in the library ?\n",
      "[[10, 2, 59, 60, 9, 4, 61, 3]]\n",
      "vous vous vous vous autre ? <end>\n",
      "Epoch 65 Loss 2.1158\n",
      "Did you plant pumpkins this year ?\n",
      "[[13, 2, 56, 57, 19, 58, 3]]\n",
      "vous vous vous ? <end>\n",
      "Epoch 66 Loss 2.0049\n",
      "Honesty will pay in the long run .\n",
      "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
      "l a a la . <end>\n",
      "Epoch 67 Loss 1.6460\n",
      "I can t believe you re giving up .\n",
      "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
      "je je je a a vous vous vous <end>\n",
      "Epoch 68 Loss 1.7650\n",
      "Germany produced many scientists .\n",
      "[[73, 74, 75, 76, 1]]\n",
      "l a de . <end>\n",
      "Epoch 69 Loss 1.4688\n",
      "Could you close the door please ?\n",
      "[[53, 2, 54, 4, 55, 18, 3]]\n",
      "vous vous vous ? <end>\n",
      "Epoch 70 Loss 1.5454\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "l l l l anniversaire hui anniversaire hui anniversaire anniversaire <end>\n",
      "Epoch 71 Loss 1.6610\n",
      "Germany produced many scientists .\n",
      "[[73, 74, 75, 76, 1]]\n",
      "est a ! <end>\n",
      "Epoch 72 Loss 1.6463\n",
      "Excuse me . Can you speak English ?\n",
      "[[67, 15, 1, 11, 2, 68, 69, 3]]\n",
      "vous vous vous vous autre ? <end>\n",
      "Epoch 73 Loss 1.6085\n",
      "Honesty will pay in the long run .\n",
      "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
      "l a a la . <end>\n",
      "Epoch 74 Loss 1.2403\n",
      "I can t believe you re giving up .\n",
      "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
      "je je vous a vous vous ? <end>\n",
      "Epoch 75 Loss 1.5323\n",
      "Are you giving me another chance ?\n",
      "[[41, 2, 14, 15, 42, 43, 3]]\n",
      "vous vous une ? <end>\n",
      "Epoch 76 Loss 1.4880\n",
      "He acted like he owned the place .\n",
      "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
      "il il il s s est possedait . <end>\n",
      "Epoch 77 Loss 1.5220\n",
      "Do you ever study in the library ?\n",
      "[[10, 2, 59, 60, 9, 4, 61, 3]]\n",
      "vous vous vous vous ? ? <end>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 Loss 1.6348\n",
      "A man s worth lies in what he is .\n",
      "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
      "<end>\n",
      "Epoch 79 Loss 1.5762\n",
      "How do we know this isn t a trap ?\n",
      "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
      "vous vous vous vous porte s ? <end>\n",
      "Epoch 80 Loss 1.2382\n",
      "Are you giving me another chance ?\n",
      "[[41, 2, 14, 15, 42, 43, 3]]\n",
      "vous vous une ? <end>\n",
      "Epoch 81 Loss 1.2653\n",
      "How do we know this isn t a trap ?\n",
      "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
      "vous vous vous vous vous ? <end>\n",
      "Epoch 82 Loss 1.4140\n",
      "Both Tom and Mary work as models .\n",
      "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
      "tom et travaillent deux deux deux . <end>\n",
      "Epoch 83 Loss 1.4398\n",
      "All three of you need to do that .\n",
      "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
      "vous vous vous autre ? <end>\n",
      "Epoch 84 Loss 1.3642\n",
      "Guess whose birthday it is today .\n",
      "[[77, 78, 79, 80, 6, 81, 1]]\n",
      "devine qui est anniversaire anniversaire aujourd hui ! <end>\n",
      "Epoch 85 Loss 1.3873\n",
      "He acted like he owned the place .\n",
      "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
      "il il est s s il possedait . <end>\n",
      "Epoch 86 Loss 1.1435\n",
      "Honesty will pay in the long run .\n",
      "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
      "l a a la . <end>\n",
      "Epoch 87 Loss 0.9720\n",
      "What he did is very wrong .\n",
      "[[8, 7, 13, 6, 33, 34, 1]]\n",
      "il est pas . <end>\n",
      "Epoch 88 Loss 1.5975\n",
      "What he did is very wrong .\n",
      "[[8, 7, 13, 6, 33, 34, 1]]\n",
      "il est a . <end>\n",
      "Epoch 89 Loss 1.1209\n",
      "I can t believe you re giving up .\n",
      "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
      "je je pas a a que vous vous . <end>\n",
      "Epoch 90 Loss 1.0190\n",
      "Germany produced many scientists .\n",
      "[[73, 74, 75, 76, 1]]\n",
      "est a . <end>\n",
      "Epoch 91 Loss 1.1572\n",
      "Do you ever study in the library ?\n",
      "[[10, 2, 59, 60, 9, 4, 61, 3]]\n",
      "vous vous vous une autre ? <end>\n",
      "Epoch 92 Loss 1.3431\n",
      "Germany produced many scientists .\n",
      "[[73, 74, 75, 76, 1]]\n",
      "est a . <end>\n",
      "Epoch 93 Loss 0.9455\n",
      "Did you plant pumpkins this year ?\n",
      "[[13, 2, 56, 57, 19, 58, 3]]\n",
      "vous vous une chance ? <end>\n",
      "Epoch 94 Loss 1.0753\n",
      "All three of you need to do that .\n",
      "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
      "vous vous de de cela cela les . <end>\n",
      "Epoch 95 Loss 1.0384\n",
      "Your idea is not entirely crazy .\n",
      "[[24, 25, 6, 26, 27, 28, 1]]\n",
      "idee n pas pas . <end>\n",
      "Epoch 96 Loss 0.9957\n",
      "Your idea is not entirely crazy .\n",
      "[[24, 25, 6, 26, 27, 28, 1]]\n",
      "idee n pas pas . <end>\n",
      "Epoch 97 Loss 1.0953\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "devine de qui est . <end>\n",
      "Epoch 98 Loss 0.9438\n",
      "Your idea is not entirely crazy .\n",
      "[[24, 25, 6, 26, 27, 28, 1]]\n",
      "idee n pas pas . <end>\n",
      "Epoch 99 Loss 1.0106\n",
      "What he did is very wrong .\n",
      "[[8, 7, 13, 6, 33, 34, 1]]\n",
      "il a a . <end>\n",
      "Epoch 100 Loss 1.0533\n",
      "How do we know this isn t a trap ?\n",
      "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
      "vous vous vous vous porte porte ? <end>\n",
      "Epoch 101 Loss 0.9544\n",
      "Don t be deceived by appearances .\n",
      "[[62, 12, 63, 64, 65, 66, 1]]\n",
      "vous pas pas les . <end>\n",
      "Epoch 102 Loss 0.8399\n",
      "I can t believe you re giving up .\n",
      "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
      "je je arrive pas a que vous vous . <end>\n",
      "Epoch 103 Loss 0.8892\n",
      "Could you close the door please ?\n",
      "[[53, 2, 54, 4, 55, 18, 3]]\n",
      "vous vous vous une ? <end>\n",
      "Epoch 104 Loss 0.7573\n",
      "Few people know the true meaning .\n",
      "[[17, 70, 20, 4, 71, 72, 1]]\n",
      "peu gens savent que cela reellement reellement <end>\n",
      "Epoch 105 Loss 0.9386\n",
      "Germany produced many scientists .\n",
      "[[73, 74, 75, 76, 1]]\n",
      "est a . <end>\n",
      "Epoch 106 Loss 0.8411\n",
      "Can I have a few minutes please ?\n",
      "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
      "je je quelques minutes vous prie ? <end>\n",
      "Epoch 107 Loss 1.0826\n",
      "Germany produced many scientists .\n",
      "[[73, 74, 75, 76, 1]]\n",
      "est a . <end>\n",
      "Epoch 108 Loss 1.0126\n",
      "A man s worth lies in what he is .\n",
      "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
      "tom et travaillent travaillent tous les deux mannequins . <end>\n",
      "Epoch 109 Loss 1.0116\n",
      "Both Tom and Mary work as models .\n",
      "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
      "tom et mary travaillent tous les deux mannequins . <end>\n",
      "Epoch 110 Loss 0.7496\n",
      "Germany produced many scientists .\n",
      "[[73, 74, 75, 76, 1]]\n",
      "est a . <end>\n",
      "Epoch 111 Loss 1.0721\n",
      "Guess whose birthday it is today .\n",
      "[[77, 78, 79, 80, 6, 81, 1]]\n",
      "devine qui c est l aujourd hui ! <end>\n",
      "Epoch 112 Loss 0.8485\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "de qui est . <end>\n",
      "Epoch 113 Loss 0.6635\n",
      "Excuse me . Can you speak English ?\n",
      "[[67, 15, 1, 11, 2, 68, 69, 3]]\n",
      "vous vous de de faire cela tous les . <end>\n",
      "Epoch 114 Loss 0.6147\n",
      "All three of you need to do that .\n",
      "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
      "vous avez de de cela tous les les . <end>\n",
      "Epoch 115 Loss 0.8463\n",
      "Guess whose birthday it is today .\n",
      "[[77, 78, 79, 80, 6, 81, 1]]\n",
      "devine de qui est anniversaire aujourd hui ! <end>\n",
      "Epoch 116 Loss 0.6376\n",
      "Can I have a few minutes please ?\n",
      "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
      "je je avoir minutes je vous prie ? <end>\n",
      "Epoch 117 Loss 0.7128\n",
      "How do we know this isn t a trap ?\n",
      "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
      "comment vous vous vous porte s il s pas ? <end>\n",
      "Epoch 118 Loss 0.7691\n",
      "Your idea is not entirely crazy .\n",
      "[[24, 25, 6, 26, 27, 28, 1]]\n",
      "votre n pas pas folle . <end>\n",
      "Epoch 119 Loss 0.6417\n",
      "Can I have a few minutes please ?\n",
      "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
      "je je avoir minutes je vous prie ? <end>\n",
      "Epoch 120 Loss 0.7838\n",
      "Guess whose birthday it is today .\n",
      "[[77, 78, 79, 80, 6, 81, 1]]\n",
      "de qui c est l aujourd hui ! <end>\n",
      "Epoch 121 Loss 0.6977\n",
      "Your idea is not entirely crazy .\n",
      "[[24, 25, 6, 26, 27, 28, 1]]\n",
      "votre n pas pas folle . <end>\n",
      "Epoch 122 Loss 0.8782\n",
      "Are you giving me another chance ?\n",
      "[[41, 2, 14, 15, 42, 43, 3]]\n",
      "vous vous une chance ? <end>\n",
      "Epoch 123 Loss 0.6978\n",
      "All three of you need to do that .\n",
      "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
      "vous avez de faire cela tous les les . <end>\n",
      "Epoch 124 Loss 0.6755\n",
      "Honesty will pay in the long run .\n",
      "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
      "l paye a la longue . <end>\n",
      "Epoch 125 Loss 0.6433\n",
      "All three of you need to do that .\n",
      "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
      "vous avez de de cela tous les les . <end>\n",
      "Epoch 126 Loss 0.7249\n",
      "Don t be deceived by appearances .\n",
      "[[62, 12, 63, 64, 65, 66, 1]]\n",
      "vous pas par les les . <end>\n",
      "Epoch 127 Loss 0.7098\n",
      "All three of you need to do that .\n",
      "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
      "vous avez de faire cela tous les trois . <end>\n",
      "Epoch 128 Loss 0.6314\n",
      "Both Tom and Mary work as models .\n",
      "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
      "tom et mary travaillent tous les deux comme mannequins . <end>\n",
      "Epoch 129 Loss 0.6101\n",
      "Honesty will pay in the long run .\n",
      "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
      "l paye a la longue . <end>\n",
      "Epoch 130 Loss 0.4823\n",
      "Your idea is not entirely crazy .\n",
      "[[24, 25, 6, 26, 27, 28, 1]]\n",
      "votre n pas pas folle . <end>\n",
      "Epoch 131 Loss 0.4098\n",
      "Do you ever study in the library ?\n",
      "[[10, 2, 59, 60, 9, 4, 61, 3]]\n",
      "vous vous vous une autre chance ? <end>\n",
      "Epoch 132 Loss 0.6361\n",
      "Are you giving me another chance ?\n",
      "[[41, 2, 14, 15, 42, 43, 3]]\n",
      "vous vous une chance ? <end>\n",
      "Epoch 133 Loss 0.4688\n",
      "Excuse me . Can you speak English ?\n",
      "[[67, 15, 1, 11, 2, 68, 69, 3]]\n",
      "vous avez de de faire cela tous les . <end>\n",
      "Epoch 134 Loss 0.4651\n",
      "Excuse me . Can you speak English ?\n",
      "[[67, 15, 1, 11, 2, 68, 69, 3]]\n",
      "vous avez de de faire cela tous les . <end>\n",
      "Epoch 135 Loss 0.5761\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "de qui est . <end>\n",
      "Epoch 136 Loss 0.5196\n",
      "Excuse me . Can you speak English ?\n",
      "[[67, 15, 1, 11, 2, 68, 69, 3]]\n",
      "vous avez de de faire cela tous les trois . <end>\n",
      "Epoch 137 Loss 0.4593\n",
      "Honesty will pay in the long run .\n",
      "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
      "l paye a la longue . <end>\n",
      "Epoch 138 Loss 0.4931\n",
      "Germany produced many scientists .\n",
      "[[73, 74, 75, 76, 1]]\n",
      "a de ! <end>\n",
      "Epoch 139 Loss 0.4873\n",
      "Excuse me . Can you speak English ?\n",
      "[[67, 15, 1, 11, 2, 68, 69, 3]]\n",
      "vous avez de de faire cela tous les trois . <end>\n",
      "Epoch 140 Loss 0.5850\n",
      "Few people know the true meaning .\n",
      "[[17, 70, 20, 4, 71, 72, 1]]\n",
      "peu gens savent ce que veut reellement dire . <end>\n",
      "Epoch 141 Loss 0.5281\n",
      "Could you close the door please ?\n",
      "[[53, 2, 54, 4, 55, 18, 3]]\n",
      "vous fermer la porte s il plait ? <end>\n",
      "Epoch 142 Loss 0.7060\n",
      "All three of you need to do that .\n",
      "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
      "vous avez de faire cela tous les trois . <end>\n",
      "Epoch 143 Loss 0.4419\n",
      "Don t be deceived by appearances .\n",
      "[[62, 12, 63, 64, 65, 66, 1]]\n",
      "vous laissez pas par les . <end>\n",
      "Epoch 144 Loss 0.6782\n",
      "Don t be deceived by appearances .\n",
      "[[62, 12, 63, 64, 65, 66, 1]]\n",
      "vous laissez pas par les . <end>\n",
      "Epoch 145 Loss 0.5639\n",
      "Do you ever study in the library ?\n",
      "[[10, 2, 59, 60, 9, 4, 61, 3]]\n",
      "comment vous vous une une autre <end>\n",
      "Epoch 146 Loss 0.4799\n",
      "He acted like he owned the place .\n",
      "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
      "il est s s il possedait possedait endroit . <end>\n",
      "Epoch 147 Loss 0.4321\n",
      "Both Tom and Mary work as models .\n",
      "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
      "tom et mary travaillent tous les deux comme mannequins . <end>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148 Loss 0.5110\n",
      "Did you plant pumpkins this year ?\n",
      "[[13, 2, 56, 57, 19, 58, 3]]\n",
      "je vous prie de excuser ! <end>\n",
      "Epoch 149 Loss 0.4430\n",
      "What he did is very wrong .\n",
      "[[8, 7, 13, 6, 33, 34, 1]]\n",
      "ce il a fait tres . <end>\n",
      "Epoch 150 Loss 0.5513\n",
      "He acted like he owned the place .\n",
      "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
      "il s est comporte comme s il l . <end>\n",
      "Epoch 151 Loss 0.4514\n",
      "He acted like he owned the place .\n",
      "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
      "il s est comporte comme s il l . <end>\n",
      "Epoch 152 Loss 0.4456\n",
      "Are you giving me another chance ?\n",
      "[[41, 2, 14, 15, 42, 43, 3]]\n",
      "vous vous une chance ? <end>\n",
      "Epoch 153 Loss 0.4984\n",
      "What he did is very wrong .\n",
      "[[8, 7, 13, 6, 33, 34, 1]]\n",
      "ce il a fait tres . <end>\n",
      "Epoch 154 Loss 0.5506\n",
      "Your idea is not entirely crazy .\n",
      "[[24, 25, 6, 26, 27, 28, 1]]\n",
      "votre n pas pas folle . <end>\n",
      "Epoch 155 Loss 0.4083\n",
      "Don t be deceived by appearances .\n",
      "[[62, 12, 63, 64, 65, 66, 1]]\n",
      "vous laissez pas par les . <end>\n",
      "Epoch 156 Loss 0.4568\n",
      "How do we know this isn t a trap ?\n",
      "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
      "comment savez vous qu il s il agit pas d un piege ? <end>\n",
      "Epoch 157 Loss 0.4933\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "de qui est . <end>\n",
      "Epoch 158 Loss 0.4121\n",
      "Are you giving me another chance ?\n",
      "[[41, 2, 14, 15, 42, 43, 3]]\n",
      "vous une autre chance ? <end>\n",
      "Epoch 159 Loss 0.4091\n",
      "Honesty will pay in the long run .\n",
      "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
      "l paye a la longue . <end>\n",
      "Epoch 160 Loss 0.3711\n",
      "Excuse me . Can you speak English ?\n",
      "[[67, 15, 1, 11, 2, 68, 69, 3]]\n",
      "vous avez de de faire cela tous les trois . <end>\n",
      "Epoch 161 Loss 0.4554\n",
      "Can I have a few minutes please ?\n",
      "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
      "puis je avoir quelques minutes vous prie ? <end>\n",
      "Epoch 162 Loss 0.3138\n",
      "What he did is very wrong .\n",
      "[[8, 7, 13, 6, 33, 34, 1]]\n",
      "ce il a fait est . <end>\n",
      "Epoch 163 Loss 0.3329\n",
      "A man s worth lies in what he is .\n",
      "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
      "la valeur d un homme reside dans ce qu il est . <end>\n",
      "Epoch 164 Loss 0.2953\n",
      "Are you giving me another chance ?\n",
      "[[41, 2, 14, 15, 42, 43, 3]]\n",
      "vous une autre chance ? <end>\n",
      "Epoch 165 Loss 0.3209\n",
      "Are you giving me another chance ?\n",
      "[[41, 2, 14, 15, 42, 43, 3]]\n",
      "vous une autre chance ? <end>\n",
      "Epoch 166 Loss 0.3102\n",
      "A man s worth lies in what he is .\n",
      "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
      "la valeur d un homme reside dans ce qu il est . <end>\n",
      "Epoch 167 Loss 0.3408\n",
      "Could you close the door please ?\n",
      "[[53, 2, 54, 4, 55, 18, 3]]\n",
      "pourriez vous porte s il vous plait ? <end>\n",
      "Epoch 168 Loss 0.4522\n",
      "Did you plant pumpkins this year ?\n",
      "[[13, 2, 56, 57, 19, 58, 3]]\n",
      "vous avez de faire cela les trois . <end>\n",
      "Epoch 169 Loss 0.2451\n",
      "I can t believe you re giving up .\n",
      "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
      "je n arrive pas a croire que vous abandonniez . <end>\n",
      "Epoch 170 Loss 0.3286\n",
      "Guess whose birthday it is today .\n",
      "[[77, 78, 79, 80, 6, 81, 1]]\n",
      "de qui c est l aujourd hui ! <end>\n",
      "Epoch 171 Loss 0.3282\n",
      "Did you plant pumpkins this year ?\n",
      "[[13, 2, 56, 57, 19, 58, 3]]\n",
      "vous avez de faire cela les trois . <end>\n",
      "Epoch 172 Loss 0.3534\n",
      "A man s worth lies in what he is .\n",
      "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
      "la valeur d un homme reside dans ce qu il est . <end>\n",
      "Epoch 173 Loss 0.4418\n",
      "Few people know the true meaning .\n",
      "[[17, 70, 20, 4, 71, 72, 1]]\n",
      "peu gens savent ce que cela veut reellement dire . <end>\n",
      "Epoch 174 Loss 0.3935\n",
      "Do you ever study in the library ?\n",
      "[[10, 2, 59, 60, 9, 4, 61, 3]]\n",
      "est ce que vous etudiez a la des fois ? <end>\n",
      "Epoch 175 Loss 0.3446\n",
      "Germany produced many scientists .\n",
      "[[73, 74, 75, 76, 1]]\n",
      "a de ! <end>\n",
      "Epoch 176 Loss 0.3011\n",
      "All three of you need to do that .\n",
      "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
      "vous avez besoin de faire cela tous les trois . <end>\n",
      "Epoch 177 Loss 0.2230\n",
      "Did you plant pumpkins this year ?\n",
      "[[13, 2, 56, 57, 19, 58, 3]]\n",
      "je vous prie de excuser ! <end>\n",
      "Epoch 178 Loss 0.2636\n",
      "Germany produced many scientists .\n",
      "[[73, 74, 75, 76, 1]]\n",
      "a de ! <end>\n",
      "Epoch 179 Loss 0.3092\n",
      "Honesty will pay in the long run .\n",
      "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
      "l paye a la longue . <end>\n",
      "Epoch 180 Loss 0.3295\n",
      "Few people know the true meaning .\n",
      "[[17, 70, 20, 4, 71, 72, 1]]\n",
      "peu de savent ce que cela veut reellement dire . <end>\n",
      "Epoch 181 Loss 0.2440\n",
      "Guess whose birthday it is today .\n",
      "[[77, 78, 79, 80, 6, 81, 1]]\n",
      "de qui c est l aujourd hui ! <end>\n",
      "Epoch 182 Loss 0.2800\n",
      "He acted like he owned the place .\n",
      "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
      "il s est comporte comme s il l . <end>\n",
      "Epoch 183 Loss 0.2785\n",
      "Do you ever study in the library ?\n",
      "[[10, 2, 59, 60, 9, 4, 61, 3]]\n",
      "est ce que vous etudiez a la des fois ? <end>\n",
      "Epoch 184 Loss 0.3439\n",
      "Don t be deceived by appearances .\n",
      "[[62, 12, 63, 64, 65, 66, 1]]\n",
      "ne pas abuser par les . <end>\n",
      "Epoch 185 Loss 0.2637\n",
      "Can I have a few minutes please ?\n",
      "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
      "puis je avoir quelques minutes vous prie ? <end>\n",
      "Epoch 186 Loss 0.3296\n",
      "Are you giving me another chance ?\n",
      "[[41, 2, 14, 15, 42, 43, 3]]\n",
      "vous une autre chance ? <end>\n",
      "Epoch 187 Loss 0.2776\n",
      "Your idea is not entirely crazy .\n",
      "[[24, 25, 6, 26, 27, 28, 1]]\n",
      "votre n est pas folle . <end>\n",
      "Epoch 188 Loss 0.3340\n",
      "Both Tom and Mary work as models .\n",
      "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
      "tom et mary travaillent tous les deux comme mannequins . <end>\n",
      "Epoch 189 Loss 0.2542\n",
      "Your idea is not entirely crazy .\n",
      "[[24, 25, 6, 26, 27, 28, 1]]\n",
      "votre n est pas folle . <end>\n",
      "Epoch 190 Loss 0.2662\n",
      "Could you close the door please ?\n",
      "[[53, 2, 54, 4, 55, 18, 3]]\n",
      "pourriez vous porte s il vous plait ? <end>\n",
      "Epoch 191 Loss 0.2921\n",
      "I can t believe you re giving up .\n",
      "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
      "je n arrive pas a croire que vous abandonniez . <end>\n",
      "Epoch 192 Loss 0.2884\n",
      "A man s worth lies in what he is .\n",
      "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
      "la valeur d un homme reside dans ce qu il est . <end>\n",
      "Epoch 193 Loss 0.2157\n",
      "Did you plant pumpkins this year ?\n",
      "[[13, 2, 56, 57, 19, 58, 3]]\n",
      "me avez vous une chance ? <end>\n",
      "Epoch 194 Loss 0.2606\n",
      "Both Tom and Mary work as models .\n",
      "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
      "tom et mary travaillent tous les deux comme mannequins . <end>\n",
      "Epoch 195 Loss 0.2657\n",
      "He acted like he owned the place .\n",
      "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
      "il s est comporte comme s il possedait endroit . <end>\n",
      "Epoch 196 Loss 0.1661\n",
      "How do we know this isn t a trap ?\n",
      "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
      "comment savez vous qu il ne s agit pas d un piege ? <end>\n",
      "Epoch 197 Loss 0.2246\n",
      "Do you ever study in the library ?\n",
      "[[10, 2, 59, 60, 9, 4, 61, 3]]\n",
      "est ce que vous etudiez a la des fois ? <end>\n",
      "Epoch 198 Loss 0.2307\n",
      "How do we know this isn t a trap ?\n",
      "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
      "comment savez vous qu il ne s agit pas d un piege ? <end>\n",
      "Epoch 199 Loss 0.2211\n",
      "Your idea is not entirely crazy .\n",
      "[[24, 25, 6, 26, 27, 28, 1]]\n",
      "votre n est pas folle . <end>\n",
      "Epoch 200 Loss 0.2474\n",
      "A man s worth lies in what he is .\n",
      "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
      "la valeur d un homme reside dans ce qu il est . <end>\n",
      "Epoch 201 Loss 0.2250\n",
      "Germany produced many scientists .\n",
      "[[73, 74, 75, 76, 1]]\n",
      "l a la longue . <end>\n",
      "Epoch 202 Loss 0.2341\n",
      "Don t be deceived by appearances .\n",
      "[[62, 12, 63, 64, 65, 66, 1]]\n",
      "ne pas abuser par les . <end>\n",
      "Epoch 203 Loss 0.2097\n",
      "Do you ever study in the library ?\n",
      "[[10, 2, 59, 60, 9, 4, 61, 3]]\n",
      "est ce que vous etudiez a la des fois ? <end>\n",
      "Epoch 204 Loss 0.2069\n",
      "He acted like he owned the place .\n",
      "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
      "il s est comporte comme s il possedait endroit . <end>\n",
      "Epoch 205 Loss 0.1725\n",
      "What he did is very wrong .\n",
      "[[8, 7, 13, 6, 33, 34, 1]]\n",
      "ce qu il est tres mal . <end>\n",
      "Epoch 206 Loss 0.2084\n",
      "Are you giving me another chance ?\n",
      "[[41, 2, 14, 15, 42, 43, 3]]\n",
      "me donnez vous autre chance ? <end>\n",
      "Epoch 207 Loss 0.1833\n",
      "He acted like he owned the place .\n",
      "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
      "il s est comporte comme s il possedait endroit . <end>\n",
      "Epoch 208 Loss 0.1603\n",
      "What he did is very wrong .\n",
      "[[8, 7, 13, 6, 33, 34, 1]]\n",
      "ce qu il est tres mal . <end>\n",
      "Epoch 209 Loss 0.1457\n",
      "Guess whose birthday it is today .\n",
      "[[77, 78, 79, 80, 6, 81, 1]]\n",
      "de qui c est l anniversaire aujourd hui ! <end>\n",
      "Epoch 210 Loss 0.2185\n",
      "Your idea is not entirely crazy .\n",
      "[[24, 25, 6, 26, 27, 28, 1]]\n",
      "votre n est pas folle . <end>\n",
      "Epoch 211 Loss 0.1791\n",
      "Can I have a few minutes please ?\n",
      "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
      "puis je avoir quelques minutes je vous ? <end>\n",
      "Epoch 212 Loss 0.1689\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "de ! <end>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 213 Loss 0.1671\n",
      "A man s worth lies in what he is .\n",
      "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
      "la valeur d un homme reside dans ce qu il est . <end>\n",
      "Epoch 214 Loss 0.1740\n",
      "Honesty will pay in the long run .\n",
      "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
      "l paye a la longue . <end>\n",
      "Epoch 215 Loss 0.1524\n",
      "Germany produced many scientists .\n",
      "[[73, 74, 75, 76, 1]]\n",
      "l a la longue . <end>\n",
      "Epoch 216 Loss 0.2355\n",
      "All three of you need to do that .\n",
      "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
      "vous avez besoin de faire cela tous les trois . <end>\n",
      "Epoch 217 Loss 0.1970\n",
      "Can I have a few minutes please ?\n",
      "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
      "puis je avoir quelques minutes je vous prie ? <end>\n",
      "Epoch 218 Loss 0.1442\n",
      "Honesty will pay in the long run .\n",
      "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
      "l paye a la longue . <end>\n",
      "Epoch 219 Loss 0.1944\n",
      "Your idea is not entirely crazy .\n",
      "[[24, 25, 6, 26, 27, 28, 1]]\n",
      "votre n est pas completement . <end>\n",
      "Epoch 220 Loss 0.1568\n",
      "How do we know this isn t a trap ?\n",
      "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
      "comment savez vous qu il ne s agit pas d un piege ? <end>\n",
      "Epoch 221 Loss 0.1909\n",
      "Honesty will pay in the long run .\n",
      "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
      "l paye a la longue . <end>\n",
      "Epoch 222 Loss 0.1511\n",
      "Do you ever study in the library ?\n",
      "[[10, 2, 59, 60, 9, 4, 61, 3]]\n",
      "est ce que vous etudiez a la des fois ? <end>\n",
      "Epoch 223 Loss 0.1674\n",
      "Honesty will pay in the long run .\n",
      "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
      "l paye a la longue . <end>\n",
      "Epoch 224 Loss 0.2266\n",
      "Excuse me . Can you speak English ?\n",
      "[[67, 15, 1, 11, 2, 68, 69, 3]]\n",
      "je vous prie de m excuser ! savez vous parler anglais ? <end>\n",
      "Epoch 225 Loss 0.1247\n",
      "How do we know this isn t a trap ?\n",
      "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
      "comment savez vous qu il ne s agit pas d un piege ? <end>\n",
      "Epoch 226 Loss 0.1806\n",
      "Honesty will pay in the long run .\n",
      "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
      "l paye a la longue . <end>\n",
      "Epoch 227 Loss 0.2206\n",
      "A man s worth lies in what he is .\n",
      "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
      "la valeur d un homme reside dans ce qu il est . <end>\n",
      "Epoch 228 Loss 0.1836\n",
      "How do we know this isn t a trap ?\n",
      "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
      "comment savez vous qu il ne s agit pas d un piege ? <end>\n",
      "Epoch 229 Loss 0.1509\n",
      "Can I have a few minutes please ?\n",
      "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
      "puis je avoir quelques minutes je vous prie ? <end>\n",
      "Epoch 230 Loss 0.1166\n",
      "How do we know this isn t a trap ?\n",
      "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
      "comment savez vous qu il ne s agit pas d un piege ? <end>\n",
      "Epoch 231 Loss 0.1336\n",
      "What he did is very wrong .\n",
      "[[8, 7, 13, 6, 33, 34, 1]]\n",
      "ce qu il est tres mal . <end>\n",
      "Epoch 232 Loss 0.1587\n",
      "Both Tom and Mary work as models .\n",
      "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
      "tom et mary travaillent tous les deux comme mannequins . <end>\n",
      "Epoch 233 Loss 0.1244\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "de ! <end>\n",
      "Epoch 234 Loss 0.1146\n",
      "Your idea is not entirely crazy .\n",
      "[[24, 25, 6, 26, 27, 28, 1]]\n",
      "votre n est pas completement folle . <end>\n",
      "Epoch 235 Loss 0.1683\n",
      "Both Tom and Mary work as models .\n",
      "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
      "tom et mary travaillent tous les deux comme mannequins . <end>\n",
      "Epoch 236 Loss 0.1521\n",
      "Guess whose birthday it is today .\n",
      "[[77, 78, 79, 80, 6, 81, 1]]\n",
      "de qui c est l anniversaire aujourd hui ! <end>\n",
      "Epoch 237 Loss 0.1183\n",
      "Excuse me . Can you speak English ?\n",
      "[[67, 15, 1, 11, 2, 68, 69, 3]]\n",
      "je vous prie de m excuser ! savez vous parler anglais ? <end>\n",
      "Epoch 238 Loss 0.1182\n",
      "Few people know the true meaning .\n",
      "[[17, 70, 20, 4, 71, 72, 1]]\n",
      "peu de savent ce que cela veut reellement dire . <end>\n",
      "Epoch 239 Loss 0.1251\n",
      "He acted like he owned the place .\n",
      "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
      "il s est comporte comme s il possedait l . <end>\n",
      "Epoch 240 Loss 0.1311\n",
      "Guess whose birthday it is today .\n",
      "[[77, 78, 79, 80, 6, 81, 1]]\n",
      "de qui c est l anniversaire aujourd hui ! <end>\n",
      "Epoch 241 Loss 0.1133\n",
      "Excuse me . Can you speak English ?\n",
      "[[67, 15, 1, 11, 2, 68, 69, 3]]\n",
      "je vous prie de m excuser ! savez vous parler anglais ? <end>\n",
      "Epoch 242 Loss 0.1442\n",
      "All three of you need to do that .\n",
      "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
      "vous avez besoin de faire cela tous les trois . <end>\n",
      "Epoch 243 Loss 0.1042\n",
      "He acted like he owned the place .\n",
      "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
      "il s est comporte comme s il possedait l . <end>\n",
      "Epoch 244 Loss 0.1197\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "de ! <end>\n",
      "Epoch 245 Loss 0.0783\n",
      "Do you ever study in the library ?\n",
      "[[10, 2, 59, 60, 9, 4, 61, 3]]\n",
      "est ce que vous etudiez a la bibliotheque des fois ? <end>\n",
      "Epoch 246 Loss 0.0962\n",
      "Do you ever study in the library ?\n",
      "[[10, 2, 59, 60, 9, 4, 61, 3]]\n",
      "est ce que vous etudiez a la bibliotheque des fois ? <end>\n",
      "Epoch 247 Loss 0.1125\n",
      "Germany produced many scientists .\n",
      "[[73, 74, 75, 76, 1]]\n",
      "l a la longue . <end>\n",
      "Epoch 248 Loss 0.1358\n",
      "Honesty will pay in the long run .\n",
      "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
      "l paye a la longue . <end>\n",
      "Epoch 249 Loss 0.1099\n",
      "Excuse me . Can you speak English ?\n",
      "[[67, 15, 1, 11, 2, 68, 69, 3]]\n",
      "je vous prie de m excuser ! savez vous parler anglais ? <end>\n",
      "Epoch 250 Loss 0.1088\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "de ! <end>\n",
      "Epoch 251 Loss 0.1131\n",
      "A man s worth lies in what he is .\n",
      "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
      "la valeur d un homme reside dans ce qu il est . <end>\n",
      "Epoch 252 Loss 0.0946\n",
      "Honesty will pay in the long run .\n",
      "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
      "l paye a la longue . <end>\n",
      "Epoch 253 Loss 0.1030\n",
      "I can t believe you re giving up .\n",
      "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
      "je n arrive pas a croire que vous abandonniez . <end>\n",
      "Epoch 254 Loss 0.1007\n",
      "I can t believe you re giving up .\n",
      "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
      "je n arrive pas a croire que vous abandonniez . <end>\n",
      "Epoch 255 Loss 0.1000\n",
      "Could you close the door please ?\n",
      "[[53, 2, 54, 4, 55, 18, 3]]\n",
      "pourriez vous fermer la porte vous plait ? <end>\n",
      "Epoch 256 Loss 0.1492\n",
      "All three of you need to do that .\n",
      "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
      "vous avez besoin de faire cela tous les trois . <end>\n",
      "Epoch 257 Loss 0.0994\n",
      "Both Tom and Mary work as models .\n",
      "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
      "tom et mary travaillent tous les deux comme mannequins . <end>\n",
      "Epoch 258 Loss 0.0764\n",
      "A man s worth lies in what he is .\n",
      "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
      "la valeur d un homme reside dans ce qu il est . <end>\n",
      "Epoch 259 Loss 0.0988\n",
      "Did you plant pumpkins this year ?\n",
      "[[13, 2, 56, 57, 19, 58, 3]]\n",
      "cette vous avez plante des citrouilles ? <end>\n",
      "Epoch 260 Loss 0.0924\n",
      "All three of you need to do that .\n",
      "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
      "vous avez besoin de faire cela tous les trois . <end>\n",
      "Epoch 261 Loss 0.0801\n",
      "Are you giving me another chance ?\n",
      "[[41, 2, 14, 15, 42, 43, 3]]\n",
      "me donnez vous une chance ? <end>\n",
      "Epoch 262 Loss 0.0927\n",
      "All three of you need to do that .\n",
      "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
      "vous avez besoin de faire cela tous les trois . <end>\n",
      "Epoch 263 Loss 0.0901\n",
      "Honesty will pay in the long run .\n",
      "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
      "l paye a la longue . <end>\n",
      "Epoch 264 Loss 0.0809\n",
      "I can t believe you re giving up .\n",
      "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
      "je n arrive pas a croire que vous abandonniez . <end>\n",
      "Epoch 265 Loss 0.0687\n",
      "Few people know the true meaning .\n",
      "[[17, 70, 20, 4, 71, 72, 1]]\n",
      "peu de savent ce que cela veut reellement dire . <end>\n",
      "Epoch 266 Loss 0.0972\n",
      "He acted like he owned the place .\n",
      "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
      "il s est comporte comme s il possedait l endroit . <end>\n",
      "Epoch 267 Loss 0.0912\n",
      "Both Tom and Mary work as models .\n",
      "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
      "tom et mary travaillent tous les deux comme mannequins . <end>\n",
      "Epoch 268 Loss 0.1025\n",
      "Could you close the door please ?\n",
      "[[53, 2, 54, 4, 55, 18, 3]]\n",
      "pourriez vous fermer la porte vous plait ? <end>\n",
      "Epoch 269 Loss 0.0874\n",
      "Did you plant pumpkins this year ?\n",
      "[[13, 2, 56, 57, 19, 58, 3]]\n",
      "cette vous avez plante des citrouilles ? <end>\n",
      "Epoch 270 Loss 0.0968\n",
      "Both Tom and Mary work as models .\n",
      "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
      "tom et mary travaillent tous les deux comme mannequins . <end>\n",
      "Epoch 271 Loss 0.0817\n",
      "Excuse me . Can you speak English ?\n",
      "[[67, 15, 1, 11, 2, 68, 69, 3]]\n",
      "je vous prie de m excuser ! savez vous parler anglais ? <end>\n",
      "Epoch 272 Loss 0.0669\n",
      "Both Tom and Mary work as models .\n",
      "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
      "tom et mary travaillent tous les deux comme mannequins . <end>\n",
      "Epoch 273 Loss 0.0898\n",
      "Don t be deceived by appearances .\n",
      "[[62, 12, 63, 64, 65, 66, 1]]\n",
      "ne pas abuser par les apparences . <end>\n",
      "Epoch 274 Loss 0.0775\n",
      "Your idea is not entirely crazy .\n",
      "[[24, 25, 6, 26, 27, 28, 1]]\n",
      "votre n est pas completement folle . <end>\n",
      "Epoch 275 Loss 0.0811\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "de ! <end>\n",
      "Epoch 276 Loss 0.0805\n",
      "Honesty will pay in the long run .\n",
      "[[86, 87, 88, 9, 4, 89, 90, 1]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l paye a la longue . <end>\n",
      "Epoch 277 Loss 0.1144\n",
      "Your idea is not entirely crazy .\n",
      "[[24, 25, 6, 26, 27, 28, 1]]\n",
      "votre n est pas completement folle . <end>\n",
      "Epoch 278 Loss 0.0685\n",
      "What he did is very wrong .\n",
      "[[8, 7, 13, 6, 33, 34, 1]]\n",
      "ce qu il est tres mal . <end>\n",
      "Epoch 279 Loss 0.0843\n",
      "Are you giving me another chance ?\n",
      "[[41, 2, 14, 15, 42, 43, 3]]\n",
      "me donnez vous une chance ? <end>\n",
      "Epoch 280 Loss 0.0725\n",
      "Both Tom and Mary work as models .\n",
      "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
      "tom et mary travaillent tous les deux comme mannequins . <end>\n",
      "Epoch 281 Loss 0.0735\n",
      "He acted like he owned the place .\n",
      "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
      "il s est comporte comme s il possedait l endroit . <end>\n",
      "Epoch 282 Loss 0.0891\n",
      "Excuse me . Can you speak English ?\n",
      "[[67, 15, 1, 11, 2, 68, 69, 3]]\n",
      "je vous prie de m excuser ! savez vous parler anglais ? <end>\n",
      "Epoch 283 Loss 0.0663\n",
      "Do you ever study in the library ?\n",
      "[[10, 2, 59, 60, 9, 4, 61, 3]]\n",
      "est ce que vous etudiez a la bibliotheque des fois ? <end>\n",
      "Epoch 284 Loss 0.0846\n",
      "Are you giving me another chance ?\n",
      "[[41, 2, 14, 15, 42, 43, 3]]\n",
      "me donnez vous une chance ? <end>\n",
      "Epoch 285 Loss 0.0771\n",
      "Can I have a few minutes please ?\n",
      "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
      "puis je avoir quelques minutes je vous prie ? <end>\n",
      "Epoch 286 Loss 0.1009\n",
      "Could you close the door please ?\n",
      "[[53, 2, 54, 4, 55, 18, 3]]\n",
      "pourriez vous fermer la porte vous plait ? <end>\n",
      "Epoch 287 Loss 0.0798\n",
      "How do we know this isn t a trap ?\n",
      "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
      "comment savez vous qu il ne s agit pas d un piege ? <end>\n",
      "Epoch 288 Loss 0.1014\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "de ! <end>\n",
      "Epoch 289 Loss 0.0747\n",
      "He acted like he owned the place .\n",
      "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
      "il s est comporte comme s il possedait l endroit . <end>\n",
      "Epoch 290 Loss 0.0755\n",
      "Both Tom and Mary work as models .\n",
      "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
      "tom et mary travaillent tous les deux comme mannequins . <end>\n",
      "Epoch 291 Loss 0.0631\n",
      "All three of you need to do that .\n",
      "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
      "vous avez besoin de faire cela tous les trois . <end>\n",
      "Epoch 292 Loss 0.0593\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "de ! <end>\n",
      "Epoch 293 Loss 0.0602\n",
      "Both Tom and Mary work as models .\n",
      "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
      "tom et mary travaillent tous les deux comme mannequins . <end>\n",
      "Epoch 294 Loss 0.0879\n",
      "What he did is very wrong .\n",
      "[[8, 7, 13, 6, 33, 34, 1]]\n",
      "ce qu il est tres mal . <end>\n",
      "Epoch 295 Loss 0.0636\n",
      "Guess whose birthday it is today .\n",
      "[[77, 78, 79, 80, 6, 81, 1]]\n",
      "de qui c est l anniversaire aujourd hui ! <end>\n",
      "Epoch 296 Loss 0.0687\n",
      "Honesty will pay in the long run .\n",
      "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
      "l honnetete paye a la . <end>\n",
      "Epoch 297 Loss 0.0543\n",
      "Honesty will pay in the long run .\n",
      "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
      "l honnetete paye a la . <end>\n",
      "Epoch 298 Loss 0.0586\n",
      "Are you giving me another chance ?\n",
      "[[41, 2, 14, 15, 42, 43, 3]]\n",
      "me donnez vous une chance ? <end>\n",
      "Epoch 299 Loss 0.0622\n",
      "Germany produced many scientists .\n",
      "[[73, 74, 75, 76, 1]]\n",
      "l a la longue . <end>\n",
      "Epoch 300 Loss 0.0644\n",
      "What he did is very wrong .\n",
      "[[8, 7, 13, 6, 33, 34, 1]]\n",
      "ce qu il est tres mal . <end>\n",
      "What a ridiculous concept !\n",
      "[[8, 5, 21, 22, 23]]\n",
      "de ! <end>\n",
      "Your idea is not entirely crazy .\n",
      "[[24, 25, 6, 26, 27, 28, 1]]\n",
      "votre idee n est pas folle . <end>\n",
      "A man s worth lies in what he is .\n",
      "[[5, 29, 30, 31, 32, 9, 8, 7, 6, 1]]\n",
      "la valeur d un homme reside dans ce qu il est . <end>\n",
      "What he did is very wrong .\n",
      "[[8, 7, 13, 6, 33, 34, 1]]\n",
      "ce qu il est tres mal . <end>\n",
      "All three of you need to do that .\n",
      "[[35, 36, 37, 2, 38, 39, 10, 40, 1]]\n",
      "vous avez besoin de faire cela tous les trois . <end>\n",
      "Are you giving me another chance ?\n",
      "[[41, 2, 14, 15, 42, 43, 3]]\n",
      "me donnez vous une chance ? <end>\n",
      "Both Tom and Mary work as models .\n",
      "[[44, 45, 46, 47, 48, 49, 50, 1]]\n",
      "tom et mary travaillent tous les deux comme mannequins . <end>\n",
      "Can I have a few minutes please ?\n",
      "[[11, 16, 51, 5, 17, 52, 18, 3]]\n",
      "puis je avoir quelques minutes je vous prie ? <end>\n",
      "Could you close the door please ?\n",
      "[[53, 2, 54, 4, 55, 18, 3]]\n",
      "pourriez vous fermer la porte vous plait ? <end>\n",
      "Did you plant pumpkins this year ?\n",
      "[[13, 2, 56, 57, 19, 58, 3]]\n",
      "cette vous avez plante des citrouilles ? <end>\n",
      "Do you ever study in the library ?\n",
      "[[10, 2, 59, 60, 9, 4, 61, 3]]\n",
      "est ce que vous etudiez a la bibliotheque des fois ? <end>\n",
      "Don t be deceived by appearances .\n",
      "[[62, 12, 63, 64, 65, 66, 1]]\n",
      "ne vous abuser par les apparences . <end>\n",
      "Excuse me . Can you speak English ?\n",
      "[[67, 15, 1, 11, 2, 68, 69, 3]]\n",
      "je vous prie de m excuser ! savez vous parler anglais ? <end>\n",
      "Few people know the true meaning .\n",
      "[[17, 70, 20, 4, 71, 72, 1]]\n",
      "peu de savent ce que cela veut reellement dire . <end>\n",
      "Germany produced many scientists .\n",
      "[[73, 74, 75, 76, 1]]\n",
      "l a la longue . <end>\n",
      "Guess whose birthday it is today .\n",
      "[[77, 78, 79, 80, 6, 81, 1]]\n",
      "de qui c est l anniversaire aujourd hui ! <end>\n",
      "He acted like he owned the place .\n",
      "[[7, 82, 83, 7, 84, 4, 85, 1]]\n",
      "il s est comporte comme s il possedait l endroit . <end>\n",
      "Honesty will pay in the long run .\n",
      "[[86, 87, 88, 9, 4, 89, 90, 1]]\n",
      "l honnetete paye a la . <end>\n",
      "How do we know this isn t a trap ?\n",
      "[[91, 10, 92, 20, 19, 93, 12, 5, 94, 3]]\n",
      "comment savez vous qu il ne s agit pas d un piege ? <end>\n",
      "I can t believe you re giving up .\n",
      "[[16, 11, 12, 95, 2, 96, 14, 97, 1]]\n",
      "je n arrive pas a croire que vous abandonniez . <end>\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 300\n",
    "\n",
    "for e in range(NUM_EPOCHS):\n",
    "    en_initial_states = encoder.init_states(BATCH_SIZE)\n",
    "    \n",
    "\n",
    "    for batch, (source_seq, target_seq_in, target_seq_out) in enumerate(dataset.take(-1)):\n",
    "        loss = train_step(source_seq, target_seq_in,\n",
    "                          target_seq_out, en_initial_states)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(e + 1, loss.numpy()))\n",
    "    \n",
    "    try:\n",
    "        predict()\n",
    "    except Exception:\n",
    "      continue\n",
    "\n",
    "test_sents = (\n",
    "    'What a ridiculous concept!',\n",
    "    'Your idea is not entirely crazy.',\n",
    "    \"A man's worth lies in what he is.\",\n",
    "    'What he did is very wrong.',\n",
    "    \"All three of you need to do that.\",\n",
    "    \"Are you giving me another chance?\",\n",
    "    \"Both Tom and Mary work as models.\",\n",
    "    \"Can I have a few minutes, please?\",\n",
    "    \"Could you close the door, please?\",\n",
    "    \"Did you plant pumpkins this year?\",\n",
    "    \"Do you ever study in the library?\",\n",
    "    \"Don't be deceived by appearances.\",\n",
    "    \"Excuse me. Can you speak English?\",\n",
    "    \"Few people know the true meaning.\",\n",
    "    \"Germany produced many scientists.\",\n",
    "    \"Guess whose birthday it is today.\",\n",
    "    \"He acted like he owned the place.\",\n",
    "    \"Honesty will pay in the long run.\",\n",
    "    \"How do we know this isn't a trap?\",\n",
    "    \"I can't believe you're giving up.\",\n",
    ")\n",
    "\n",
    "for test_sent in test_sents:\n",
    "    test_sequence = normalize_string(test_sent)\n",
    "    predict(test_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TensorFlow] *",
   "language": "python",
   "name": "conda-env-TensorFlow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
